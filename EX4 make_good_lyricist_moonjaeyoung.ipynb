{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "terminal-antarctica",
   "metadata": {},
   "source": [
    "# ğŸ’» ë©‹ì§„ ì‘ì‚¬ê°€ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-atmosphere",
   "metadata": {},
   "source": [
    "## Step1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-silver",
   "metadata": {},
   "source": [
    "ì´ë²ˆ í”„ë¡œì íŠ¸ì— ì‚¬ìš©í•  ë°ì´í„°ëŠ” LMS cloud ~/aiffel/lyricist/data/lyrics ê²½ë¡œì— ìˆëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-wildlife",
   "metadata": {},
   "source": [
    "## Step2. ë°ì´í„° ì½ì–´ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-african",
   "metadata": {},
   "source": [
    "ì´ë²ˆ í”„ë¡œì íŠ¸ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ ë° ë°ì´í„° ì •ë³´ë¥¼ ì¶œë ¥í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southeast-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° í¬ê¸°: 187088\n",
      "Examples:\n",
      " [' There must be some kind of way outta here', 'Said the joker to the thief', \"There's too much confusion\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# ì—¬ëŸ¬ê°œì˜ txt íŒŒì¼ì„ ëª¨ë‘ ì½ì–´ì„œ raw_corpus ì— ë‹´ìŠµë‹ˆë‹¤.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"ë°ì´í„° í¬ê¸°:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-paraguay",
   "metadata": {},
   "source": [
    "## Step3. ë°ì´í„° ì •ì œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-morning",
   "metadata": {},
   "source": [
    "ìì—°ì–´ ì²˜ë¦¬ì—ì„œëŠ” ë°ì´í„°ê°€ ì•Œë§ì€ ëª©ì ì— ë§ê²Œ ì „ì²˜ë¦¬ê°€ ë¼ìˆì§€ ì•Šì€ ìƒíƒœë¼ë©´, ìš©ë„ì— ë§ê²Œ í† í°í™”(Tokenization) ë° ì •ì œ(cleaning) ê³¼ì •ì„ ê±°ì¹œë‹¤.\n",
    "\n",
    " \"Time is an illusion. Lunchtime double so!\" ì´ë¼ëŠ” ë¬¸ì¥ì´ ì£¼ì–´ì¡Œì„ë•Œ, ì´ ë¬¸ì¥ì€ í† í°í™”ê°€ ë‹¨ìˆœí•˜ë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œë¡œ í† í°í™” ì‘ì—…ì„ ìˆ˜í–‰í•˜ë‹¤ ë³´ë©´, ì˜ˆìƒì¹˜ ëª»í•œ ê²½ìš°ê°€ ìƒê¸´ë‹¤.\n",
    " \n",
    " ì‚¬ìš© ëª©ì , ì˜ë„ì— ë§ê²Œ í† í°í™” í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì§œì•¼í•œë‹¤. ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì—¬ëŸ¬ íŠ¹ìˆ˜ ê¸°í˜¸ê°€ ë“¤ì–´ê°€ì§€ ì•Šì€ ë‹¨ì–´ë¥¼ ë½‘ì•„ì•¼ í•˜ê¸° ë•Œë¬¸ì— íŠ¹ìˆ˜ë¬¸ì, ê³µë°±, ëŒ€ë¬¸ìë¥¼ ì¡°ì ˆí•´ ë‹¨ì–´ë§Œ ë½‘ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œë‹¤.\n",
    " \n",
    " \n",
    "> - ì •ì œ : ê°–ê³ ìˆëŠ” ë°ì´í„°ë¡œë¶€í„° ë…¸ì´ì¦ˆ ë°ì´í„°ë¥¼ ì œê±°í•œë‹¤.\n",
    "> - ì •ê·œí™” : ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ í‘œí˜„ ë°©ë²•ì´ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì„ í†µí•©ì‹œì¼œ ê°™ì€ ë‹¨ì–´ë¡œ ë§Œë“¤ì–´ì¤€ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infinite-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence2 = sentence.split(' ')\n",
    "    if len(sentence2) > 13:\n",
    "        return 0 \n",
    "    else:\n",
    "        sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-hungarian",
   "metadata": {},
   "source": [
    "ë³¸ì¸ì€ í† í°í™” í–ˆì„ ë•Œ í† í°ì˜ ê°¯ìˆ˜ê°€ 15ê°œë¥¼ ë„˜ì–´ê°€ì§€ ì•ŠëŠ” ë¬¸ì¥ ë°ì´í„°ë¥¼ ê¶Œí•œë‹¤ëŠ” ì¡°ê±´ì„ ë°›ì•˜ê¸°ì—, <start>, <end>ë¥¼ ì œì™¸í•œ ë‹¨ì–´ì˜ ê¸¸ì´ê°€ 13ê°œë¥¼ ì´ˆê³¼í•˜ì§€ ì•ŠëŠ” ì¡°ê±´ë¬¸ì„ ê±¸ì—ˆë‹¤.\n",
    "    \n",
    "   sentenceê°€ 13ì„ ì´ˆê³¼í• ê²½ìš° 0ì„ ë°˜í™˜í•˜ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ sentenceë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "future-saturn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> there must be some kind of way outta here <end>',\n",
       " '<start> said the joker to the thief <end>',\n",
       " '<start> there s too much confusion <end>',\n",
       " '<start> i can t get no relief business men , they drink my wine <end>',\n",
       " '<start> plowman dig my earth <end>',\n",
       " '<start> none were level on the mind <end>',\n",
       " '<start> nobody up at his word <end>',\n",
       " '<start> hey , hey no reason to get excited <end>',\n",
       " '<start> the thief he kindly spoke <end>',\n",
       " '<start> there are many here among us <end>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    if preprocessed_sentence == 0:\n",
    "        pass\n",
    "    else:\n",
    "        corpus.append(preprocessed_sentence)\n",
    "\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-harassment",
   "metadata": {},
   "source": [
    "ì´í›„ì— ì •ì œëœ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ì•„ë†“ì€ preprocessed_sentenceì˜ ìš”ì†Œê°€ \"0\"(ë‹¨ì–´ì˜ ê°¯ìˆ˜ê°€ 13ê°œ ì´ìƒì¸ ë¬¸ì¥)ì¼ê²½ìš° ì§€ë‚˜ì¹˜ê³  \"0\"ì´ ì•„ë‹ˆë¼ë©´ corpusì— ì¶”ê°€í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "discrete-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  62 271 ...   0   0   0]\n",
      " [  2 118   6 ...   0   0   0]\n",
      " [  2  62  17 ...   0   0   0]\n",
      " ...\n",
      " [  2  75  45 ...   3   0   0]\n",
      " [  2  49   5 ...   0   0   0]\n",
      " [  2  13 633 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f95a4dc9e10>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-occupation",
   "metadata": {},
   "source": [
    "Tensorflowì˜ Tokenizerì™€ pad_sequencesë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í°í™” í•œë‹¤.\n",
    "ë³¸ì¸ì€ ë¬¸ì¥ì„ í† í°í™” í–ˆì„ë•Œ 15ê°œë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šìœ¼ë ¤ê³  pad_sequencesì˜ maxlenì¸ìë¡œ\n",
    "15ì˜ ê°’ì„ ì£¼ì—ˆì§€ë§Œ, ë°ì´í„°ë¥¼ ì œì™¸ì‹œí‚¤ëŠ”ê²Œ ì•„ë‹Œ ìŠ¬ë¼ì´ì‹±ì˜ ê¸°ëŠ¥ì„ ê°€ì§€ë¯€ë¡œ maxlenì„\n",
    "ì§€ì›Œì•¼ í–ˆë‹¤.\n",
    "\n",
    "ë‹¨ì–´ì¥ì˜ í¬ê¸°ëŠ” 12000ì´ìƒ ì´ë¼ëŠ” ì¡°ê±´ì´ ìˆìœ¼ë¯€ë¡œ, 12000ê°œì˜ ë‹¨ì–´ë¥¼ ê¸°ì–µí• ìˆ˜ ìˆëŠ” tokenizerë¥¼ ìƒì„±í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clean-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrow-sierra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  62 271  27  94 546  20  86 742  90   3   0   0   0]\n",
      "[ 62 271  27  94 546  20  86 742  90   3   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  \n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-mounting",
   "metadata": {},
   "source": [
    "tensorì—ì„œ ê°ê°ì˜ ë§ˆì§€ë§‰ í† í°ì„ ì˜ë¼ë‚´ì„œ ì…ë ¥í•  ì†ŒìŠ¤ ë¬¸ì¥ì„ ìƒì„±í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "absent-isolation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156013, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-camping",
   "metadata": {},
   "source": [
    "## Step4. í‰ê°€ ë°ì´í„°ì…‹ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-chicken",
   "metadata": {},
   "source": [
    "sklearn ëª¨ë“ˆì˜ train_test_split()í•¨ìˆ˜ë¥¼ ì´ìš©í•´ í•™ìŠµë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼\n",
    "8:2 ë¹„ìœ¨ë¡œ ë¶„ë¦¬í–ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monetary-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                          tgt_input,\n",
    "                                                          test_size = 0.2,\n",
    "                                                          random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "possible-passenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124810, 14)\n",
      "Target Train: (124810, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "formal-intellectual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-reply",
   "metadata": {},
   "source": [
    "## Step5. ì¸ê³µì§€ëŠ¥ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-centre",
   "metadata": {},
   "source": [
    "ì‹¤ìŠµ ë‚´ìš©ì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” 1ê°œì˜ Embedding ë ˆì´ì–´ 2ê°œì˜ LSTM ë ˆì´ì–´, 1ê°œì˜ Denseë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ìˆë‹¤. ê° ë ˆì´ì–´ì˜ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "\n",
    "> - Embedding : ì¸ê°„ì˜ ì–¸ì–´(ìì—°ì–´)ëŠ” ìˆ˜ì¹˜í™” ë˜ìˆì§€ ì•Šì€ ë°ì´í„°ê¸° ë•Œë¬¸ì— ë°”ë¡œ ëª¨ë¸ì— ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤. ê·¸ë˜ì„œ ìì—°ì–´ ì²˜ë¦¬ì—ì„œ íŠ¹ì§• ì¶”ì¶œì„ í•´ì¤˜ì•¼ í•˜ëŠ”ë° ì´ê²ƒì´ \"ì–¸ì–´ì˜ ë²¡í„°í™”\"ì´ë‹¤. ì´ëŸ° ë²¡í„°í™”ì˜ ê³¼ì •ì„ Word Embeddingì´ë¼ê³  í•œë‹¤.\n",
    "> - LSTM : (Long Short Term Memory)ì˜ ì•½ìë¡œ ê¸°ì¡´ì˜ RNNì´ ì¶œë ¥ê³¼ ë¨¼ ìœ„ì¹˜ì— ìˆëŠ” ì •ë³´ë¥¼ ê¸°ì–µí•  ìˆ˜ ì—†ë‹¤ëŠ” ë‹¨ì ì„ ë³´ì™„í•˜ì—¬ ì¥/ë‹¨ê¸° ê¸°ì–µì„ ê°€ëŠ¥í•˜ê²Œ ì„¤ê³„í•œ ì‹ ê²½ë§ì˜ êµ¬ì¡°ì´ë‹¤.\n",
    "> - Dense : ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ì‹ ê²½ë§ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë ˆì´ì–´ë¡œ ì…ë ¥ê³¼ ì¶œë ¥ì„ ëª¨ë‘ ì—°ê²°í•´ì¤€ë‹¤.\n",
    "> - hidden layer : ì¸ê³µ ì‹ ê²½ë§ì˜ íˆë“  ë ˆì´ì–´ëŠ” ì…ë ¥ ë ˆì´ì–´ì™€ ì¶œë ¥ ë ˆì´ì–´ ì‚¬ì´ì— ìˆëŠ” ë ˆì´ì–´ë¡œ, ì—¬ê¸°ì„œ ì¸ê³µ ë‰´ëŸ°ì€ ê°€ì¤‘ ì…ë ¥ ì„¸íŠ¸ë¥¼ ë°›ì•„ í™œì„±í™” í•¨ìˆ˜ë¥¼ í†µí•´ ì¶œë ¥ì„ ìƒì„±í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "parallel-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-priest",
   "metadata": {},
   "source": [
    "- embedding sizeë¥¼ 256ìœ¼ë¡œ ì£¼ì—ˆë‹¤ëŠ”ê±´, í•˜ë‚˜ì˜ tokenì„ 256ê°œì˜ ë²¡í„°ë¡œ ë°”ê¿”ì¤€ë‹¤ëŠ” ëœ»ì´ë‹¤. ë‚˜ì•„ê°€ ëª¨ë¸ ê°œì„ í•˜ê¸° íŒŒíŠ¸ì—ì„œ ì—¬ëŸ¬ íŒŒë¼ë¯¸í„° ê°’ì„ ì£¼ì–´ ê²°ê³¼ë¥¼ í™•ì¸ í•´ë³´ë„ë¡ í•˜ì.\n",
    "\n",
    "- hidden sizeëŠ” ì€ë‹‰ ìƒíƒœì˜ í¬ê¸°ë¥¼ ì •ì˜í•œë‹¤. RNNì˜ ìš©ëŸ‰ì„ ëŠ˜ë¦°ë‹¤ê³  ë³´ë©´ë˜ë©°, ì¤‘ì†Œí˜• ëª¨ë¸ì˜ ê²½ìš° ë³´í†µ 128, 256, 512, 1024ë“±ì˜ ê°’ì„ ê°–ëŠ”ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dynamic-celebrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 14, 12001])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "model(src_sample)\n",
    "model(src_sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "least-award",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-lottery",
   "metadata": {},
   "source": [
    "- optimizerë€ ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµì—ì„œ ì‹¤ì œë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ê°±ì‹ ì‹œí‚¤ëŠ” ë¶€ë¶„ì„ ì˜ë¯¸í•œë‹¤. ì´ë²ˆ ì‹¤ìŠµì—ì„œ ì‚¬ìš©í•  optimizerëŠ” Adamì´ë‹¤.\n",
    "  Adamì€ í˜„ì¬ ê°€ì¥ ìì£¼ ì‚¬ìš©ë˜ëŠ” optimizerë¡œ í­ë„“ì€ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì³ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ê³  í•œë‹¤.\n",
    "  Adamë§ê³ ë„ cs231nì— ì†Œê°œí•œ Stochastic Gradient Descent(SGD), NAG, RMSProp, AdaGrad ë“±ì´ ìˆë‹¤.\n",
    "  \n",
    "  \n",
    "\n",
    "- loss(ì†ì‹¤ í•¨ìˆ˜)ë€ ì»´í“¨í„°ëŠ” ì²˜ìŒì— ëœë¤ê°’ì„ ëŒ€ì…í•´ ë¬¸ì œë¥¼ í’€ì–´ë³¸ë‹¤. ê²°ê³¼ì™€ ì‹¤ì œ ì •ë‹µê°„ì˜ ê°„ê²© ì¦‰, ì°¨ì´ë¥¼ ìµœëŒ€í•œ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ\n",
    "  ê°’ì„ ëŒ€ì…í•˜ê²Œëœë‹¤. ì´ ê°’ì˜ ì°¨ì´ë¥¼ lossë¼ê³  í•œë‹¤. ì´ lossë¥¼ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµì´ ì§„í–‰ëœë‹¤. lossì˜ ì¢…ë¥˜ì—ëŠ” \n",
    "  MSE, MRSE, Binary Crossentropyë“±ì´ ìˆìœ¼ë©° ì´ë²ˆ ì‹¤ìŠµì— ì‚¬ìš©í•  lossëŠ” Categorical Crossentropyë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 157s 317ms/step - loss: 4.0284\n",
      "Epoch 2/10\n",
      "268/487 [===============>..............] - ETA: 1:10 - loss: 3.0834"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "copyrighted-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "established-instrument",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i m not gonna crack <end> '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence = \"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-seeking",
   "metadata": {},
   "source": [
    "## Step5. ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ê°œì„ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-gardening",
   "metadata": {},
   "source": [
    "### (1) hidden_size ê°’ ê°ì†Œì‹œì¼œë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "suspended-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 72s 143ms/step - loss: 4.4185\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 70s 143ms/step - loss: 3.3409\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 70s 143ms/step - loss: 3.1391\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 70s 143ms/step - loss: 3.0003\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 70s 142ms/step - loss: 2.9041\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 69s 142ms/step - loss: 2.8166\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 70s 143ms/step - loss: 2.7474\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 70s 143ms/step - loss: 2.6843\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 70s 143ms/step - loss: 2.6311\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 70s 143ms/step - loss: 2.5674\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 512\n",
    "model2 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model2.compile(loss=loss, optimizer=optimizer)\n",
    "history2 = model2.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "boxed-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 43s 83ms/step - loss: 4.7102\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 41s 83ms/step - loss: 3.4388\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 41s 83ms/step - loss: 3.3071\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 41s 83ms/step - loss: 3.1462\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 41s 83ms/step - loss: 3.0386\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 41s 83ms/step - loss: 2.9700\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 41s 83ms/step - loss: 2.9009\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 41s 83ms/step - loss: 2.8401\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 41s 84ms/step - loss: 2.7789\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 41s 84ms/step - loss: 2.7238\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 256\n",
    "model3 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model3.compile(loss=loss, optimizer=optimizer)\n",
    "history3 = model3.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "continuing-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 32s 60ms/step - loss: 5.0712\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 30s 61ms/step - loss: 3.5111\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 30s 61ms/step - loss: 3.3391\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 30s 61ms/step - loss: 3.1844\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 30s 61ms/step - loss: 3.0724\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 30s 61ms/step - loss: 2.9993\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 29s 60ms/step - loss: 2.9464\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 29s 60ms/step - loss: 2.8859\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 30s 61ms/step - loss: 2.8444\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 30s 60ms/step - loss: 2.8062\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 128\n",
    "model4 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model4.compile(loss=loss, optimizer=optimizer)\n",
    "history4 = model4.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-start",
   "metadata": {},
   "source": [
    "embedding_sizeë¥¼ ê·¸ëŒ€ë¡œ ë‘ê³  hidden_sizeë§Œ ê°ì†Œ ì‹œì¼°ë”ë‹ˆ í•™ìŠµ ì‹œê°„ì„ ì¤„ì§€ë§Œ lossê°’ì€ ëŒ€í­ ì¦ê°€í–ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-venture",
   "metadata": {},
   "source": [
    "### (2) embedding size ê°’ ë³€ê²½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-circumstances",
   "metadata": {},
   "source": [
    "imbedding sizeë¥¼ 256ìœ¼ë¡œ ì£¼ì—ˆë‹¤ëŠ”ê±´, í•˜ë‚˜ì˜ tokenì„ 300ê°œì˜ ë²¡í„°ë¡œ ë°”ê¿”ì¤€ë‹¤ëŠ” ëœ»ì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "powered-cherry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 155s 308ms/step - loss: 4.1067\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 153s 313ms/step - loss: 3.1095\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 153s 313ms/step - loss: 2.9488\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 153s 313ms/step - loss: 2.8248\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 153s 313ms/step - loss: 2.7208\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 153s 313ms/step - loss: 2.6295\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 153s 313ms/step - loss: 2.5450\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 152s 312ms/step - loss: 2.4647\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 151s 309ms/step - loss: 2.3891\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 152s 311ms/step - loss: 2.3211\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "hidden_size = 1024\n",
    "model5 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model5.compile(loss=loss, optimizer=optimizer)\n",
    "history5 = model5.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "artificial-while",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 152s 302ms/step - loss: 4.1280\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 149s 305ms/step - loss: 3.1498\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 148s 304ms/step - loss: 2.9924\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 149s 305ms/step - loss: 2.8699\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 148s 304ms/step - loss: 2.7666\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 148s 304ms/step - loss: 2.6898\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 148s 304ms/step - loss: 2.6092\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 148s 304ms/step - loss: 2.5344\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 148s 304ms/step - loss: 2.4647\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 148s 303ms/step - loss: 2.4051\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "hidden_size = 1024\n",
    "model6 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model6.compile(loss=loss, optimizer=optimizer)\n",
    "history6 = model6.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-qatar",
   "metadata": {},
   "source": [
    "hidden_sizeë¥¼ ê°ì†Œ ì‹œì¼°ì„ë•Œë³´ë‹¤ ë³€í™”ìœ¨ì€ í¬ê²Œ ì—†ì§€ë§Œ ê·¸ë˜ë„ lossê°’ì´ ì¦ê°€í•¨ì„ ë³¼ ìˆ˜ ìˆì—ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-panama",
   "metadata": {},
   "source": [
    "### (3) ê·¸ ì™¸ì˜ ì‹œë„ë“¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "demonstrated-amber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 69s 137ms/step - loss: 4.4768\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 68s 139ms/step - loss: 3.3127\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 68s 139ms/step - loss: 3.1057\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 68s 140ms/step - loss: 2.9909\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 68s 140ms/step - loss: 2.9162\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 68s 140ms/step - loss: 2.8430\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 68s 140ms/step - loss: 2.7738\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 68s 140ms/step - loss: 2.7236\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 68s 139ms/step - loss: 2.6630\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 68s 139ms/step - loss: 2.6199\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "hidden_size = 512\n",
    "model7 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model7.compile(loss=loss, optimizer=optimizer)\n",
    "history7 = model7.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "relevant-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 69s 136ms/step - loss: 4.4924\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 67s 137ms/step - loss: 3.2911\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 67s 137ms/step - loss: 3.1434\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 67s 138ms/step - loss: 3.0350\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 67s 138ms/step - loss: 2.9495\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 67s 138ms/step - loss: 2.8756\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 67s 138ms/step - loss: 2.8195\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 67s 137ms/step - loss: 2.7545\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 67s 138ms/step - loss: 2.6976\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 67s 137ms/step - loss: 2.6479\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "hidden_size = 512\n",
    "model8= TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model8.compile(loss=loss, optimizer=optimizer)\n",
    "history8 = model8.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "consistent-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 39s 75ms/step - loss: 4.8274\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 37s 75ms/step - loss: 3.4392\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 37s 75ms/step - loss: 3.3268\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 37s 75ms/step - loss: 3.2393\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 37s 76ms/step - loss: 3.1567\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 37s 76ms/step - loss: 3.0799\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 37s 76ms/step - loss: 3.0268\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 37s 76ms/step - loss: 2.9838\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 37s 76ms/step - loss: 2.9436\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 37s 76ms/step - loss: 2.9025\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "hidden_size = 256\n",
    "model8= TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model8.compile(loss=loss, optimizer=optimizer)\n",
    "history8 = model8.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "intensive-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 27s 50ms/step - loss: 5.1672\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 3.7942\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 3.4487\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 3.3244\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 3.2004\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 3.1176\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 3.0595\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 3.0139\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 2.9708\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 25s 50ms/step - loss: 2.9346\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "hidden_size = 128\n",
    "model10= TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model10.compile(loss=loss, optimizer=optimizer)\n",
    "history10 = model10.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "agricultural-spider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 41s 79ms/step - loss: 4.7558\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 39s 79ms/step - loss: 3.4441\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 39s 80ms/step - loss: 3.3226\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 39s 80ms/step - loss: 3.1945\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 39s 80ms/step - loss: 3.0918\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 39s 80ms/step - loss: 3.0191\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 39s 80ms/step - loss: 2.9646\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 39s 80ms/step - loss: 2.9160\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 39s 80ms/step - loss: 2.8813\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 39s 80ms/step - loss: 2.8364\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "hidden_size = 256\n",
    "model11= TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model11.compile(loss=loss, optimizer=optimizer)\n",
    "history11 = model11.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sonic-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "487/487 [==============================] - 29s 55ms/step - loss: 5.1376\n",
      "Epoch 2/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 3.5679\n",
      "Epoch 3/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 3.4268\n",
      "Epoch 4/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 3.3522\n",
      "Epoch 5/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 3.2601\n",
      "Epoch 6/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 3.1663\n",
      "Epoch 7/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 3.0966\n",
      "Epoch 8/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 3.0419\n",
      "Epoch 9/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 2.9873\n",
      "Epoch 10/10\n",
      "487/487 [==============================] - 27s 55ms/step - loss: 2.9439\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "hidden_size = 128\n",
    "model12= TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model12.compile(loss=loss, optimizer=optimizer)\n",
    "history12=  model12.fit(dataset, epochs=10)"
   ]
  },
  {
   "attachments": {
    "s%20s%20s.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "crude-municipality",
   "metadata": {},
   "source": [
    "![s%20s%20s.png](attachment:s%20s%20s.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-posting",
   "metadata": {},
   "source": [
    "## íšŒê³ \n",
    "\n",
    "> - ì´ë¯¸ì§€ ì²˜ë¦¬ì™€ ë‹¤ë¥´ê²Œ ìì—°ì–´ì˜ ì „ì²˜ë¦¬ ê³¼ì •ì€ ëª©ì ì— ë§ê²Œ í† í°í™” ë° ì •ì œ, ì •ê·œí™” ê³¼ì •ì„ ê±°ì³ì•¼ í•œë‹¤.\n",
    "> - Embeddingì´ë€ ì‚¬ëŒì˜ ì–¸ì–´(ìì—°ì–´)ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆê²Œ ìˆ˜ì¹˜í™” í•´ì£¼ëŠ” ê³¼ì •ì„ ëœ»í•œë‹¤.\n",
    "> - buffer_sizeê°’ì„ src_inputì˜ ê¸¸ì´ì™€ ê°™ê²Œ í˜¹ì€ ë” í¬ê²Œ ì¤˜ì•¼í•œë‹¤. ê°’ì„ ì‘ê²Œ ì¤„ ê²½ìš°, ëª‡ ë¶€ë¶„ì„ ë†“ì¹˜ê³  ì…”í”Œ í•  ìˆ˜ ìˆë‹¤.\n",
    "> - embedding_sizeë¥¼ ì¤„ì¼ìˆ˜ë¡ í•™ìŠµ ì†ë„ê°€ ëŠë¦¬ë‹¤. hidden_sizeë¥¼ ì¤„ì¼ìˆ˜ë¡ í•™ìŠµ ì†ë„ê°€ ë¹ ë¥´ë‹¤.\n",
    "> - embedding_sizeë¥¼ ì¤„ì¼ìˆ˜ë¡ lossì˜ ê°’ì´ ì¦ê°€ í–ˆì§€ë§Œ ì„œì„œíˆ ì¦ê°€í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ë‹¤.\n",
    "> - hidden_sizeë¥¼ ì¤„ì¼ìˆ˜ë¡, embeddingê³¼ ë§ˆì°¬ê°€ì§€ê³  lossê°€ ì¦ê°€í–ˆì§€ë§Œ ìƒëŒ€ì ìœ¼ë¡œ ë§ì´ ì¦ê°€í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ë‹¤. lossì— ì˜í–¥ì´ ë” í° ëª¨ìŠµì„ ë³´ì˜€ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-kennedy",
   "metadata": {},
   "source": [
    "## ìë£Œ ì¶œì²˜\n",
    " - ì •ì œ, ì •ê·œí™”, í† í°í™” : <https://wikidocs.net/21698>\n",
    " - pad_sequences : https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    " - Embedding : https://simpling.tistory.com/1\n",
    " - LSTM : http://www.incodom.kr/LSTM\n",
    " - Dense : https://ssongnote.tistory.com/13\n",
    " - Hidden layer : https://www.techopedia.com/definition/33264/hidden-layer-neural-networks\n",
    " - imbedding size : https://algopoolja.tistory.com/34\n",
    " - hidden size : https://wikidocs.net/22886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-polymer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
